{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51c8a01c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "from pathlib import Path\n",
    "\n",
    "import datasets\n",
    "from datasets import Dataset, DatasetDict, load_dataset\n",
    "from more_itertools import chunked\n",
    "from PIL import Image\n",
    "from tqdm.auto import tqdm\n",
    "import json\n",
    "\n",
    "Image.MAX_IMAGE_PIXELS = None\n",
    "\n",
    "\n",
    "def load_json(file_path: Path, is_jsonl: bool = False):\n",
    "    if is_jsonl:\n",
    "        with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "            return [json.loads(line) for line in f]\n",
    "    else:\n",
    "        with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "            return json.loads(f.read())\n",
    "\n",
    "\n",
    "def write_json(data: list, file_path: Path, is_jsonl: bool = False, **kwargs):\n",
    "    if is_jsonl:\n",
    "        with open(file_path, \"w\", encoding=\"utf-8\") as f:\n",
    "            for item in data:\n",
    "                f.write(json.dumps(item, ensure_ascii=False) + \"\\n\")\n",
    "    else:\n",
    "        with open(file_path, \"w\", encoding=\"utf-8\") as f:\n",
    "            json.dump(data, f, ensure_ascii=True, **kwargs)\n",
    "            # f.write(orjson.dumps(data).decode(\"utf-8\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2513254",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = load_dataset(\"initiacms/XLRS-Bench-lite\")\n",
    "# ds = datasets.load_from_disk(\"~/download/datasets/XLRS-Bench-lite\")\n",
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0be53782",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = ds[\"train\"].to_list()\n",
    "all_bytes = []\n",
    "for it in data:\n",
    "    for img in it[\"image\"]:\n",
    "        all_bytes.append(img[\"bytes\"])\n",
    "set_all_bytes = set(all_bytes)\n",
    "len(all_bytes), len(set_all_bytes)\n",
    "del all_bytes\n",
    "import gc\n",
    "\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a9cb6ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_base = Path(\"/path/to/save/XLRS-imgs\")\n",
    "bytes2idx = dict()\n",
    "\n",
    "\n",
    "def func(bytes, path):\n",
    "    img = Image.open(io.BytesIO(bytes))\n",
    "    img.save(path)\n",
    "\n",
    "\n",
    "with ThreadPoolExecutor(max_workers=16) as executor:\n",
    "    futs = []\n",
    "    for idx, bytes in tqdm(enumerate(set_all_bytes), total=len(set_all_bytes)):\n",
    "        bytes2idx[bytes] = idx\n",
    "        # using jpg or png according to your needs\n",
    "        # which may affect evaluation results, but jpg is smaller in size\n",
    "        path = img_base / f\"{idx}.jpg\"\n",
    "        if path.exists():\n",
    "            continue\n",
    "        fut = executor.submit(func, bytes, str(path))\n",
    "        futs.append(fut)\n",
    "        if len(futs) >= 128:\n",
    "            for fut in as_completed(futs):\n",
    "                _ = fut.result()\n",
    "            futs = []\n",
    "    for fut in as_completed(futs):\n",
    "        _ = fut.result()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77a0e787",
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "\n",
    "new_data = []\n",
    "for it in data:\n",
    "    it = deepcopy(it)\n",
    "    new_image = []\n",
    "    for img in it[\"image\"]:\n",
    "        idx = bytes2idx[img[\"bytes\"]]\n",
    "        path = img_base / f\"{idx}.jpg\"\n",
    "        new_image.append(str(path))\n",
    "    it[\"image\"] = new_image\n",
    "    new_data.append(it)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91d78f45",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = DatasetDict({\"train\": Dataset.from_list(new_data)})\n",
    "ds[\"train\"].to_json(\"XLRS-Bench.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b6d675f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = load_json(Path(\"XLRS-Bench.json\"))\n",
    "target_dir = Path(\"/path/to/converted_xlrs_data/\")\n",
    "categories = set([it[\"category\"] for it in data])\n",
    "write_json({k: [] for k in categories}, target_dir / \"categories.json\")\n",
    "target_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e535485",
   "metadata": {},
   "outputs": [],
   "source": [
    "for it in tqdm(data):\n",
    "    unique_id = f\"{it['category']}/{it['index']}\"\n",
    "    unique_id = unique_id.replace(\"/\", \"__\").replace(\" \", \"_\")\n",
    "    annotation = {\n",
    "        \"question\": it[\"question\"],\n",
    "        \"options\": it[\"multi-choice options\"],\n",
    "        \"answer\": it[\"answer\"],\n",
    "        \"category\": it[\"category\"],\n",
    "        # \"subcategory\": sample.get(\"l2-category\", \"default\"),  # 已去除\n",
    "        \"original_path\": it[\"path\"],\n",
    "        \"original_index\": it[\"index\"],\n",
    "        \"unique_id\": unique_id,\n",
    "    }\n",
    "    # i_ps = [i.replace(\"/home/wfx524866/download/\", \"\") for i in it[\"image\"]]\n",
    "    i_ps = [\"/\".join(i.split(\"/\")[-2:]) for i in it[\"image\"]]\n",
    "    # for i in i_ps:\n",
    "    #     assert (Path(\"/home/wfx524866/download/\") / i).exists(), i\n",
    "    if len(i_ps) == 1:\n",
    "        # 单图\n",
    "        annotation |= {\n",
    "            \"image_path\": i_ps[0],\n",
    "        }\n",
    "    else:\n",
    "        # 多图\n",
    "        annotation |= {\n",
    "            \"image_paths\": i_ps,\n",
    "            \"is_multi_image\": True,\n",
    "        }\n",
    "    # print(annotation)\n",
    "    # break\n",
    "    write_json(\n",
    "        annotation,\n",
    "        # f\"/data/oss_bucket_0/wangfengxiang/datasets/deepeyes/converted_data/xlrs/{unique_id}.json\",\n",
    "        target_dir / f\"{unique_id}.json\",\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
